{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity\n",
    "\n",
    "---\n",
    "\n",
    "# Author\n",
    "\n",
    "    - Unai Gurbindo\n",
    "    - Jaume Guasch\n",
    "---\n",
    "\n",
    "# Date\n",
    "*December 22th, 2023*\n",
    "\n",
    "---\n",
    "\n",
    "# Statement\n",
    "\n",
    "Use data set and description of task Semantic Textual Similarity in SemEval 2012.\n",
    "\n",
    "Implement some approaches to detect paraphrase using sentence similarity metrics.\n",
    "\n",
    "- Explore some lexical dimensions.\n",
    "- Explore the syntactic dimension alone.\n",
    "- Explore the combination of both previous.\n",
    "\n",
    "Add new components at your choice (optional).\n",
    "\n",
    "Already generated word or sentence embeddings models are not allowed, such as BERT.\n",
    "\n",
    "Compare and comment the results achieved by these approaches among them and among the official results.\n",
    "\n",
    "Send files to raco in IHLT STS Project before the oral presentation:\n",
    "\n",
    "- Jupyter notebook: sts-[Student1]-[Student2].ipynb\n",
    "\n",
    "- Slides: sts-[Student1]-[Student2].pdf\n",
    "\n",
    "---\n",
    "\n",
    "# Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: regex in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\unaig\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (0.7.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\unaig\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from deep-translator) (4.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from deep-translator) (2.28.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BDCDF9A610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/deep-translator/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BDCDF9A910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/deep-translator/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BDCDF9AAC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/deep-translator/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BDCDF9AC70>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/deep-translator/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001BDCDF9AE20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/deep-translator/\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E848C4F3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/textdistance/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E848C4F6A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/textdistance/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E848C4F9A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/textdistance/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E848C4FB50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/textdistance/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E848C4FD00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/textdistance/\n",
      "ERROR: Could not find a version that satisfies the requirement textdistance (from versions: none)\n",
      "ERROR: No matching distribution found for textdistance\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# import textdistance as td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files in Data Folder: test-gold.tgz, train.tgz\n",
    "\n",
    "# Unzip Files\n",
    "# !tar -xzf ./Data/test-gold.tgz\n",
    "# !tar -xzf ./Data/train.tgz\n",
    "\n",
    "# Read train data and concatenate into one file (read all the txt files in the train folder)\n",
    "train_path = './train'\n",
    "test_path = './test-gold'\n",
    "\n",
    "# Read Train files\n",
    "train_files = [\"MSRpar\",\"MSRvid\",\"SMTeuroparl\"]\n",
    "train_data = pd.DataFrame(columns = ['Sentence 1', 'Sentence 2', 'GS', 'Origin'])\n",
    "for file in train_files:   \n",
    "    \n",
    "    sentences_path= train_path + '/STS.input.' +  file + '.txt'\n",
    "    with open(sentences_path, 'r') as f:\n",
    "        sentences = f.read().splitlines()\n",
    "        sentences = [s.split('\\t') for s in sentences]\n",
    "        \n",
    "    input_sentences = pd.DataFrame(sentences, columns = ['Sentence 1', 'Sentence 2']) \n",
    "    \n",
    "    input_gold_score = pd.read_table(train_path + '/STS.gs.' + file+ '.txt', names=['GS'])\n",
    "    \n",
    "    input=  pd.concat([input_sentences, input_gold_score], axis=1)  \n",
    "    input['Origin'] = file[:-4]                          \n",
    "    train_data = pd.concat([train_data, input], ignore_index=True)      \n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop_duplicates(subset = ['Sentence 1', 'Sentence 2', 'GS'], keep = False, inplace = True)\n",
    "train_target = train_data['GS'] \n",
    "train_data.drop(columns=['index', 'GS'], inplace=True)\n",
    "\n",
    "# Read test files\n",
    "test_files = [\"MSRpar\", \"MSRvid\", \"SMTeuroparl\", \"surprise.OnWN\", \"surprise.SMTnews\"]\n",
    "test_data = pd.DataFrame(columns = ['Sentence 1', 'Sentence 2', 'GS', 'Origin'])\n",
    "for file in test_files:   \n",
    "    \n",
    "    sentences_path= test_path + '/STS.input.' +  file + '.txt'\n",
    "    with open(sentences_path, 'r') as f:\n",
    "        sentences = f.read().splitlines()\n",
    "        sentences = [s.split('\\t') for s in sentences]\n",
    "        \n",
    "    input_sentences = pd.DataFrame(sentences, columns = ['Sentence 1', 'Sentence 2']) \n",
    "    \n",
    "    input_gold_score = pd.read_table(test_path + '/STS.gs.' + file+ '.txt', names=['GS'])\n",
    "    \n",
    "    input=  pd.concat([input_sentences, input_gold_score], axis=1)  \n",
    "    input['Origin'] = file[:-4]                          \n",
    "    test_data = pd.concat([test_data, input], ignore_index=True)\n",
    "test_data.reset_index(inplace=True)\n",
    "test_data.drop_duplicates(subset = ['Sentence 1', 'Sentence 2', 'GS'], keep = False, inplace = True)\n",
    "test_target = test_data['GS']\n",
    "test_data.drop(columns=['index', 'GS'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>Action is needed quickly, which is why we deci...</td>\n",
       "      <td>It is urgent and that is why we have decided t...</td>\n",
       "      <td>SMTeuro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>One could indeed wish for more and for improve...</td>\n",
       "      <td>We can actually want more and better, but I th...</td>\n",
       "      <td>SMTeuro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>(Parliament accepted the oral amendment)</td>\n",
       "      <td>(Parliament accepted the oral amendment)</td>\n",
       "      <td>SMTeuro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>- My party has serious reservations about Comm...</td>\n",
       "      <td>My party serious reservations about the regula...</td>\n",
       "      <td>SMTeuro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>He saw a red rose.</td>\n",
       "      <td>He drove a rose colored car.</td>\n",
       "      <td>SMTeuro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence 1  \\\n",
       "0     But other sources close to the sale said Viven...   \n",
       "1     Micron has declared its first quarterly profit...   \n",
       "2     The fines are part of failed Republican effort...   \n",
       "3     The American Anglican Council, which represent...   \n",
       "4     The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "...                                                 ...   \n",
       "2229  Action is needed quickly, which is why we deci...   \n",
       "2230  One could indeed wish for more and for improve...   \n",
       "2231           (Parliament accepted the oral amendment)   \n",
       "2232  - My party has serious reservations about Comm...   \n",
       "2233                                 He saw a red rose.   \n",
       "\n",
       "                                             Sentence 2   Origin  \n",
       "0     But other sources close to the sale said Viven...       MS  \n",
       "1     Micron's numbers also marked the first quarter...       MS  \n",
       "2     Perry said he backs the Senate's efforts, incl...       MS  \n",
       "3     The American Anglican Council, which represent...       MS  \n",
       "4     The technology-laced Nasdaq Composite Index <....       MS  \n",
       "...                                                 ...      ...  \n",
       "2229  It is urgent and that is why we have decided t...  SMTeuro  \n",
       "2230  We can actually want more and better, but I th...  SMTeuro  \n",
       "2231         (Parliament accepted the oral amendment)    SMTeuro  \n",
       "2232  My party serious reservations about the regula...  SMTeuro  \n",
       "2233                      He drove a rose colored car.   SMTeuro  \n",
       "\n",
       "[2222 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pre-processing strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spell checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words: {'sentennce', 'wordds', 'examplo'}\n",
      "Corrected text: this is an example sentence with some misspelled words\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Create a SpellChecker instance\n",
    "spell = SpellChecker(distance=3)\n",
    "\n",
    "# Example text with some intentional spelling errors\n",
    "text = \"this is an examplo sentennce with some misspelled wordds\"\n",
    "\n",
    "# Split the text into words\n",
    "words = text.split()\n",
    "\n",
    "# Find and print misspelled words\n",
    "misspelled = spell.unknown(words)\n",
    "print(\"Misspelled words:\", misspelled)\n",
    "\n",
    "# Correct the misspelled words\n",
    "for word in misspelled:\n",
    "    corrected_word = spell.correction(word)\n",
    "    text = text.replace(word, corrected_word)\n",
    "\n",
    "print(\"Corrected text:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Translation language for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"keep it up you're great\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "sentence= \"keep it up, you are awesome\"\n",
    "\n",
    "sentence_translate_es=GoogleTranslator(source='auto', target='es').translate(sentence) \n",
    "GoogleTranslator(source='auto', target='en').translate(sentence_translate_es) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n",
      "File \u001b[1;32mc:\\Users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unaig\\anaconda3\\envs\\py38ml\\lib\\site-packages\\spacy\\util.py:331\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ngrams with words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ngrams with characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Models Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
